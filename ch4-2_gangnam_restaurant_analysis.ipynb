{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loving-external",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/yoonkt200/python-data-analysis/master/img/this_is_data_anal.png\" width=\"200\" height=\"200\"><br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-messenger",
   "metadata": {},
   "source": [
    "## 4.2 강남역 맛집 리뷰로 알아보는 감성 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-recommendation",
   "metadata": {},
   "source": [
    "분류 모델의 가장 대표적인 활용 방법 중 하나는 바로 감성 분류이다. 감성 분류란 문서를 긍정의견 또는 부정의견으로 나누어 분류하는 것이다. 이번엔 강남역 맛집 리뷰 데이터를 활용하여 감성 분류를 수행해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-sterling",
   "metadata": {},
   "source": [
    "### step.1 크롤링: 네이버 플레이스 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-globe",
   "metadata": {},
   "source": [
    "첫 번째 단계에서는 크롤링을 이용하여 감성 분류에 필요한 데이터를 직접 수집하자. 이번에 크롤링할 데이터는 네이버 플레이스의 음식점 랭킹 정보이다. 네이버 플레이스 API는 별도의 라이브러리 설치나 개발자 등록 없이 source_url에 검색 규칙을 추가하는 것만으로도 크롤링을 적용할 수 있다. 아래의 코드와 같이 start, display, query, sortingOrder 파라미터로 검색 규칙을 추가하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-relative",
   "metadata": {},
   "source": [
    "- start, display : 검색 결과를 얼마만큼 보여줄지에 관련된 파라미터\n",
    "- query : 검색하고 싶은 장소나 음식점에 대한 검색어\n",
    "- sortingOrder : 어떤 방식으로 검색 결과를 정렬할지에 대한 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-cradle",
   "metadata": {},
   "source": [
    "검색 규칙을 추가한 url_concat에 request.get 함수를 적용하면 json 형태의 검색 결과 데이터를 얻을 수 있다. 그리고 이를 jason.loads 함수로 변환하면 파이썬의 dictionary와 동일한 형태로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "irish-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8-*-\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-asian",
   "metadata": {},
   "source": [
    "### step.2 텍스트 전처리: 분류 모델 피처로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-registration",
   "metadata": {},
   "source": [
    "이번 단계에는 텍스트 데이터를 감성 분류의 피처로 사용할 수 있도록 하는 텍스트 전처리 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-macintosh",
   "metadata": {},
   "source": [
    "- 한글 텍스트로 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adult-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "auburn-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>y</th>\n",
       "      <th>ko_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>친절하시고 깔끔하고 좋았습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>조용하고 고기도 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>갈비탕과 냉면 육회비빔밥이 맛있습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>대체적으로 만족하나와인의 구성이 살짝 아쉬움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>고기도 맛있고 서비스는 더 최고입니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  y                   ko_text\n",
       "0      5  1          친절하시고 깔끔하고 좋았습니다\n",
       "1      5  1                조용하고 고기도 굿\n",
       "2      4  1      갈비탕과 냉면 육회비빔밥이 맛있습니다\n",
       "3      4  1  대체적으로 만족하나와인의 구성이 살짝 아쉬움\n",
       "4      5  1      고기도 맛있고 서비스는 더 최고입니다"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/jaeyoon89/python-data-analysis/chapter4/review_data.csv\")\n",
    "df['ko_text'] = df['review'].apply(lambda x: text_cleaning(x))\n",
    "del df['review']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-basis",
   "metadata": {},
   "source": [
    "형태소를 추출하는 전처리 과정도 진행하자. 아래 코드에서 형태소/품사의 형태로 데이터를 추출하는 get_pos()라는 함수를 정의했고 이 함수에 대한 테스트 코드 실행 결과는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-beauty",
   "metadata": {},
   "source": [
    "- 형태소 단위의 추출 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "great-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['친절하시고/Adjective', '깔끔하고/Adjective', '좋았습니다/Adjective']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# konlpy라이브러리로 텍스트 데이터에서 형태소를 추출합니다.\n",
    "def get_pos(x):\n",
    "    tagger = Okt()\n",
    "    pos = tagger.pos(x)\n",
    "    pos = ['{}/{}'.format(word,tag) for word, tag in pos]\n",
    "    return pos\n",
    "\n",
    "# 형태소 추출 동작을 테스트합니다.\n",
    "result = get_pos(df['ko_text'][0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc6a74",
   "metadata": {},
   "source": [
    "이제 텍스트 데이터의 마지막 전처리 과정이다. 이번 단계의 핵심은 텍스트 데이터를 분류 모델에 학습이 가능한 데이터셋으로 만드는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55673e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broad-pride",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-f8aa91c73d72>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-f8aa91c73d72>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    X = index_vectorizer.fit_transform(df['ko_text'].tolist()\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 형태소를 벡터 형태의 학습 데이터셋(X 데이터)으로 변환합니다.\n",
    "index_vectorizer = CountVectorizer(tokenizer = lambda x: get_pos(x))\n",
    "X = index_vectorizer.fit_transform(df['ko_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-missouri",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
