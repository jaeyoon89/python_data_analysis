{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loving-external",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/yoonkt200/python-data-analysis/master/img/this_is_data_anal.png\" width=\"200\" height=\"200\"><br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-messenger",
   "metadata": {},
   "source": [
    "## 4.2 강남역 맛집 리뷰로 알아보는 감성 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-recommendation",
   "metadata": {},
   "source": [
    "분류 모델의 가장 대표적인 활용 방법 중 하나는 바로 감성 분류이다. 감성 분류란 문서를 긍정의견 또는 부정의견으로 나누어 분류하는 것이다. 이번엔 강남역 맛집 리뷰 데이터를 활용하여 감성 분류를 수행해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-sterling",
   "metadata": {},
   "source": [
    "### step.1 크롤링: 네이버 플레이스 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-globe",
   "metadata": {},
   "source": [
    "첫 번째 단계에서는 크롤링을 이용하여 감성 분류에 필요한 데이터를 직접 수집하자. 이번에 크롤링할 데이터는 네이버 플레이스의 음식점 랭킹 정보이다. 네이버 플레이스 API는 별도의 라이브러리 설치나 개발자 등록 없이 source_url에 검색 규칙을 추가하는 것만으로도 크롤링을 적용할 수 있다. 아래의 코드와 같이 start, display, query, sortingOrder 파라미터로 검색 규칙을 추가하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-relative",
   "metadata": {},
   "source": [
    "- start, display : 검색 결과를 얼마만큼 보여줄지에 관련된 파라미터\n",
    "- query : 검색하고 싶은 장소나 음식점에 대한 검색어\n",
    "- sortingOrder : 어떤 방식으로 검색 결과를 정렬할지에 대한 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-cradle",
   "metadata": {},
   "source": [
    "검색 규칙을 추가한 url_concat에 request.get 함수를 적용하면 json 형태의 검색 결과 데이터를 얻을 수 있다. 그리고 이를 jason.loads 함수로 변환하면 파이썬의 dictionary와 동일한 형태로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "irish-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8-*-\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-asian",
   "metadata": {},
   "source": [
    "### step.2 텍스트 전처리: 분류 모델 피처로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-registration",
   "metadata": {},
   "source": [
    "이번 단계에는 텍스트 데이터를 감성 분류의 피처로 사용할 수 있도록 하는 텍스트 전처리 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-macintosh",
   "metadata": {},
   "source": [
    "- 한글 텍스트로 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adult-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "auburn-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>y</th>\n",
       "      <th>ko_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>친절하시고 깔끔하고 좋았습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>조용하고 고기도 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>갈비탕과 냉면 육회비빔밥이 맛있습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>대체적으로 만족하나와인의 구성이 살짝 아쉬움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>고기도 맛있고 서비스는 더 최고입니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  y                   ko_text\n",
       "0      5  1          친절하시고 깔끔하고 좋았습니다\n",
       "1      5  1                조용하고 고기도 굿\n",
       "2      4  1      갈비탕과 냉면 육회비빔밥이 맛있습니다\n",
       "3      4  1  대체적으로 만족하나와인의 구성이 살짝 아쉬움\n",
       "4      5  1      고기도 맛있고 서비스는 더 최고입니다"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/jaeyoon89/python-data-analysis/chapter4/review_data.csv\")\n",
    "df['ko_text'] = df['review'].apply(lambda x: text_cleaning(x))\n",
    "del df['review']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-basis",
   "metadata": {},
   "source": [
    "형태소를 추출하는 전처리 과정도 진행하자. 아래 코드에서 형태소/품사의 형태로 데이터를 추출하는 get_pos()라는 함수를 정의했고 이 함수에 대한 테스트 코드 실행 결과는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-beauty",
   "metadata": {},
   "source": [
    "- 형태소 단위의 추출 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "great-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['친절하시고/Adjective', '깔끔하고/Adjective', '좋았습니다/Adjective']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# konlpy라이브러리로 텍스트 데이터에서 형태소를 추출합니다.\n",
    "def get_pos(x):\n",
    "    tagger = Okt()\n",
    "    pos = tagger.pos(x)\n",
    "    pos = ['{}/{}'.format(word,tag) for word, tag in pos]\n",
    "    return pos\n",
    "\n",
    "# 형태소 추출 동작을 테스트합니다.\n",
    "result = get_pos(df['ko_text'][0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc92928",
   "metadata": {},
   "source": [
    "이제 텍스트 데이터의 마지막 전처리 과정이다. 이번 단계의 핵심은 텍스트 데이터를 분류 모델에 학습이 가능한 데이터셋으로 만드는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a4066",
   "metadata": {},
   "source": [
    "텍스트 데이터를 연산 가능한 피처로 만드는 방법은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27ad37",
   "metadata": {},
   "source": [
    "- 1. raw 데이터셋 : 데이터 프레임의 텍스트 데이터에 해당한다.\n",
    "- 2. 말뭉치 : raw 데이터셋으로부터 말뭉치를 생성한다. 이 말뭉치는 형태소의 서로 다른 고유한 셋을 가지고 있다.\n",
    "- 3. 학습 데이터셋 : 서로 다른 6개의 형태소는 각 텍스트 데이터의 벡터 길이가 된다. 만약 텍스트에 해당 단어가 존재하면 벡터의 값을 1로, 존재하지 않으면 벡터의 값을 0으로 할당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba903f",
   "metadata": {},
   "source": [
    "파이썬에선느 sklearn.feature_extraction.text 라이브러리의 CountVectorizer라는 클래스를 통해 이 작업을 쉽게 수행할 수 있다. CountVectorizer 클래스의 tokenizer 파라미터는 텍스트 데이터의 전처리 방식을 입력하는 것이고, 이 객체에 df['ko_text'].tolist()을 입력값으로 fit_transform을 실행하면 학습 데이터셋을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b4819",
   "metadata": {},
   "source": [
    "- 분류 모델의 학습 데이터로 변환하기 : corpus index 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broad-pride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545, 3030)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 형태소를 벡터 형태의 학습 데이터셋(X 데이터)으로 변환합니다.\n",
    "index_vectorizer = CountVectorizer(tokenizer = lambda x: get_pos(x))\n",
    "X = index_vectorizer.fit_transform(df['ko_text'].tolist())\n",
    "print(X.shape)                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229e541",
   "metadata": {},
   "source": [
    "학습 데이터셋과 말뭉치가 올바르게 생성되었는지를 확인해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab42324",
   "metadata": {},
   "source": [
    "- 분류 모델의 학습 데이터로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5f7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'친절하시고/Adjective': 2647, '깔끔하고/Adjective': 428, '좋았습니다/Adjective': 2403, '조용하고/Adjective': 2356, '고..\n"
     ]
    }
   ],
   "source": [
    "print(str(index_vectorizer.vocabulary_)[:100]+\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a58e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친절하시고 깔끔하고 좋았습니다\n",
      "  (0, 2647)\t1\n",
      "  (0, 428)\t1\n",
      "  (0, 2403)\t1\n"
     ]
    }
   ],
   "source": [
    "print(df['ko_text'][0])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b35cf",
   "metadata": {},
   "source": [
    "하지만 텍스트 데이터에 중복되는 형태소가 존재한다면 어떻게 될까? 만약 '너무 좋았습니다', '너무 너무 너무 좋았습니다' 라는 두 텍스트 데이터가 있다면 중복되는 형태소 '너무' 가 존재하기 때문에 이 둘은 같은 데이터로 변환된다. 이 문제를 해결하기 위해 텍스트를 피처로 만드는 다른 방법인 TF-IDF를 적용해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354bff5",
   "metadata": {},
   "source": [
    "- 분류 모델의 학습 데이터로 변환하기 : TF-IDF로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cba0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545, 3030)\n",
      "  (0, 2647)\t0.5548708693511647\n",
      "  (0, 2403)\t0.48955631270748484\n",
      "  (0, 428)\t0.6726462183300624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# TF-IDF 방법으로, 형태소를 벡터 형태의 학습 데이터셋(X 데이터)으로 변환한다.\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "X = tfidf_vectorizer.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442b6dd",
   "metadata": {},
   "source": [
    "'친절하시고 깔끔하고 좋았습니다' 라는 텍스트 데이터가 TF-IDF 피처로 표현된 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dd557",
   "metadata": {},
   "source": [
    "### Step.3 분류: 긍정/부정 리뷰 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9be470",
   "metadata": {},
   "source": [
    "이제 감성 분류를 위한 데이터셋이 모두 준비 되었다. sklearn.model_selection에서 제공하는 train_test_split() 함수를 사용하여 훈련 데이터셋과 테스트 데이터셋으로 데이터를 분리하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1b45d",
   "metadata": {},
   "source": [
    "- 분류 모델링 : 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6282df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 3030)\n",
      "(164, 3030)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.30)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c08ba7",
   "metadata": {},
   "source": [
    "- 분류 모델링 : 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03451b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9430e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 모델을 학습한다.\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "y_pred_probability = lr.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3226f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.85\n",
      "Precision : 0.854\n",
      "Recall : 1.000\n",
      "F1 : 0.921\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델의 성능을 평가한다.\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc4614",
   "metadata": {},
   "source": [
    "실행 결과 대부분의 평가 수치가 높은 것을 볼 수 있다. 이렇게 분류기의 성능이 비정상적으로 높은 경우 모델의 평가 방법이나 과정을 의심해볼 필요가 있다. 이러한 의심을 직접 해소하기 위해 Confusion Matrix를 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd507f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  24]\n",
      " [  0 140]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix를 출력한다.\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5d14d",
   "metadata": {},
   "source": [
    "하지만 출력 결과가 이상하다. 이 분류 모델은 모든 데이터를 '1'로 예측하고 있다. 모델이 하나의 결과만을 예측하도록 잘못된 학습을 한 것이다. 이러한 현상을 클래스의 불균형 문제라고 한다. 이는 데이터의 Positive sample(1)과 Negative sample(0)의 비율이 크게 차이가 나는 경우에 발생한다. 그래서 적절한 샘플링 방법을 통해 클래스의 불균형 문제를 해경해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187279f",
   "metadata": {},
   "source": [
    "- 클래스 불균형 문제 해결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072cc3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0     53\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y가 0과 1을 각각 얼마나 가지고 있는지 출력한다.\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0efe28",
   "metadata": {},
   "source": [
    "이제 두 클래스간의 비율을 동일하게 맞춰주는 방법을 생각해볼 수 있다. 다음 코드는 클래스를 1:1 비율로 샘플링하기 위해 y가 1인 50개의 샘플, y가 0인 50개의 샘플을 임의로 추출한다. 그리고 이 데이터를 다시 훈련 데이터셋(70개)과 테스트 데이터셋 (30개)로 분리하는 방법을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bdb491",
   "metadata": {},
   "source": [
    "- 클래스 불균형 문제 해결하기 : 1:1 비율의 랜덤 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eb0c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 비율로 랜덤 샘플링을 수행한다.\n",
    "positive_random_idx = df[df['y']==1].sample(50, random_state=30).index.tolist()\n",
    "negative_random_idx = df[df['y']==0].sample(50, random_state=30).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c05ab2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 3030)\n",
      "(30, 3030)\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 데이터로 데이터셋을 나눈다.\n",
    "random_idx = positive_random_idx + negative_random_idx\n",
    "sample_X = X[random_idx, :]\n",
    "y = df['y'][random_idx]\n",
    "x_train, x_test, y_train, y_test = train_test_split(sample_X,y,test_size=0.30)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bf1f9",
   "metadata": {},
   "source": [
    "균형을 맞춰 샘플링한 데이터로 학습과 평가를 진행해보자. 이전보다 모델의 정확도는 떨어졌지만, 상식적인 수준에서 납득할 수 있을 정도의 성능으로 변하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a9749",
   "metadata": {},
   "source": [
    "- 로지스틱 회귀 모델 다시 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6a00a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 모델을 학습한다.\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "y_pred_probability = lr.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff7fa54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.67\n",
      "Precision : 1.000\n",
      "Recall : 0.412\n",
      "F1 : 0.583\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델의 성능을 평가한다.\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed5589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
